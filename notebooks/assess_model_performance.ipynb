{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import os, sys\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "HOME = os.environ[\"HOME\"]\n",
    "CARDIAC_COMA_REPO = f\"{HOME}/01_repos/CardiacCOMA/\"\n",
    "import os; os.chdir(CARDIAC_COMA_REPO)\n",
    "\n",
    "from config.cli_args import overwrite_config_items\n",
    "from config.load_config import load_yaml_config, to_dict\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import Image\n",
    "\n",
    "import pandas as pd\n",
    "import shlex\n",
    "from subprocess import check_output\n",
    "\n",
    "import pickle as pkl\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import surgeon_pytorch\n",
    "#from surgeon_pytorch import Inspect, get_layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import embed\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# import model.Model3D\n",
    "# from utils.helpers import get_coma_args, get_lightning_module, get_datamodule\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pyvista as pv\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helpers import get_datamodule, get_lightning_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mlflow_helpers import get_model_pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARDIAC_GWAS_REPO = f\"{HOME}/01_repos/CardiacGWAS\"\n",
    "CARDIAC_COMA_REPO = f\"/{HOME}/01_repos/CardiacCOMA/\"\n",
    "MLRUNS_DIR = f\"{CARDIAC_GWAS_REPO}/mlruns\"\n",
    "import os; os.chdir(CARDIAC_COMA_REPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overwrite_ref_config(ref_config, run_info):\n",
    "    \n",
    "    '''\n",
    "    This is a workaround for adjusting the configuration of those runs that didn't have a YAML configuration file logged as an artifact.\n",
    "    '''\n",
    "    \n",
    "    config = deepcopy(ref_config)\n",
    "    config.network_architecture.latent_dim = int(run_info[\"params.latent_dim\"])\n",
    "    config.loss.regularization.weight = float(run_info[\"params.w_kl\"])\n",
    "    config.optimizer.parameters.lr = float(run_info[\"params.lr\"])\n",
    "    config.sample_sizes = [100, 100, 100, 100]\n",
    "    \n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_runs_df = pd.read_csv(f\"{CARDIAC_GWAS_REPO}/good_runs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_pretrained_weights(exp_id, run_id):\n",
    "    \n",
    "    # run_info = runs_df.loc[experiment_id, run_id].to_dict()\n",
    "    chkpt_dir = f\"{CARDIAC_COMA_REPO}/mlruns/{exp_id}/{run_id}/checkpoints\"\n",
    "    if not os.path.exists(chkpt_dir):\n",
    "        chkpt_dir = f\"{CARDIAC_COMA_REPO}/mlruns/{exp_id}/{run_id}/artifacts/restored_model_checkpoint\"\n",
    "    \n",
    "    chkpt_file = os.path.join(chkpt_dir, os.listdir(chkpt_dir)[0])\n",
    "    \n",
    "    model_pretrained_weights = torch.load(chkpt_file, map_location=torch.device('cpu'))[\"state_dict\"]\n",
    "    \n",
    "    # Remove \"model.\" prefix from state_dict's keys.\n",
    "    _model_pretrained_weights = {k.replace(\"model.\", \"\"): v for k, v in model_pretrained_weights.items()}\n",
    "\n",
    "    return _model_pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_w = widgets.Select(options=sorted(good_runs_df.run_id.to_list()))\n",
    "\n",
    "@interact\n",
    "def load_model(run_id=run_w):\n",
    "    global _run_id, config, weights\n",
    "    _run_id = run_id\n",
    "    config_file = f\"{mlruns_dir}/1/{run_id}/artifacts/config.yaml\"    \n",
    "    config = load_yaml_config(config_file)\n",
    "    config.sample_sizes = [100, 100, 100, 100]\n",
    "    # pprint(to_dict(config))\n",
    "    \n",
    "    exp_id = \"1\"\n",
    "    weights = get_model_pretrained_weights(exp_id, _run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = get_datamodule(config, perform_setup=True)\n",
    "model = get_lightning_module(config, dm)\n",
    "model.model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. get z dataframe\n",
    "# 2. get mean and std\n",
    "# 3. pass z_mean through model\n",
    "\n",
    "exp_id = '1'\n",
    "run_id = _run_id\n",
    "\n",
    "# GOSR2\n",
    "z_var = \"z001\"\n",
    "\n",
    "# PLN\n",
    "z_var = \"z003\"\n",
    "\n",
    "# TTN\n",
    "z_var = \"z003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{CARDIAC_COMA_REPO}/mlruns/{exp_id}/{_run_id}/artifacts/output/latent_vector.csv\")\n",
    "df = df.set_index(\"ID\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mae = 1000\n",
    "for row in list(df.iterrows()):\n",
    "    \n",
    "    dev = np.array(row[1]) - z    \n",
    "    mae = np.sum(dev**2)    \n",
    "    \n",
    "    if mae < min_mae:\n",
    "        min_mae = mae\n",
    "        id_min = row[0]\n",
    "        dev_min = dev\n",
    "        \n",
    "print(id_min, min_mae, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sphere = vedo.Sphere(res=params[\"mesh_resolution\"]).to_trimesh()\n",
    "# conn = sphere.faces # connectivity\n",
    "# conn = np.c_[np.ones(conn.shape[0]) * 3, conn].astype(int)  # add column of 3, as required by PyVista\n",
    "\n",
    "import random\n",
    "pv.set_plot_theme(\"document\")\n",
    "\n",
    "faces, _ = pkl.load(open(\"data/cardio/faces_and_downsampling_mtx_frac_0.1_LV.pkl\", \"rb\")).values()\n",
    "faces = np.c_[np.ones(faces.shape[0]) * 3, faces].astype(int)\n",
    "\n",
    "color_palette = list(pv.colors.color_names.values())\n",
    "random.shuffle(color_palette)\n",
    "\n",
    "def f(z_dev=widgets.IntSlider(min=-3,max=3)):\n",
    "    \n",
    "    df = pd.read_csv(f\"{CARDIAC_COMA_REPO}/mlruns/{exp_id}/{_run_id}/artifacts/output/latent_vector.csv\").drop(\"ID\", axis=1)\n",
    "    z_mean, z_std = df.mean(), df.std()\n",
    "    z = torch.Tensor(z_mean + z_dev * z_std)\n",
    "    # z = torch.zeros(z_mean.shape)\n",
    "    s = model.model.decoder(z).detach().numpy()[0]\n",
    "\n",
    "    pl = pv.Plotter(notebook=True, off_screen=False, polygon_smoothing=False)\n",
    "    mesh = pv.PolyData(s, faces)\n",
    "    pl.add_mesh(mesh, show_edges=False, point_size=1.5, color=color_palette[0], opacity=0.5)\n",
    "    pl.show(interactive=True, interactive_update=True)\n",
    "    \n",
    "interact(f);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.decoder.requires_grad_ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dm.dataset[1]['s']\n",
    "s_hat = model(s)[0][0]\n",
    "mse(s, s_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
